{
  "id": 3250490,
  "global_id": "Z2lkOi8vaGFja2Vyb25lL1JlcG9ydC8zMjUwNDkw",
  "url": "https://hackerone.com/reports/3250490",
  "title": "Disk Space Exhaustion leading to a Denial of Service (DoS)",
  "state": "Closed",
  "substate": "spam",
  "severity_rating": "medium",
  "readable_substate": "Spam",
  "created_at": "2025-07-14T02:20:06.105Z",
  "submitted_at": "2025-07-14T02:20:06.341Z",
  "is_member_of_team?": false,
  "is_organization_group_member?": false,
  "reporter": {
    "disabled": false,
    "username": "tryhackplanet",
    "url": "/tryhackplanet",
    "profile_picture_urls": {
      "small": "https://profile-photos.hackerone-user-content.com/variants/byo4mwzx3c8wr6xbumk70qowqtsb/d86f3034cedc97192c6e25b49fb25d458f11529df403793678d43ead36f13cc4"
    },
    "is_me?": false,
    "cleared": false,
    "verified": false,
    "hackerone_triager": false,
    "hacker_mediation": false
  },
  "team": {
    "id": 35663,
    "url": "https://hackerone.com/curl",
    "handle": "curl",
    "profile_picture_urls": {
      "small": "https://profile-photos.hackerone-user-content.com/variants/000/035/663/2faf4c279d437d64bfda6d23d62ce1833813a4d9_original.png/36bca6668139d77be42208d896968344ae7a76c55ee0f8b0f28281ccd492ff02",
      "medium": "https://profile-photos.hackerone-user-content.com/variants/000/035/663/2faf4c279d437d64bfda6d23d62ce1833813a4d9_original.png/19c85a12ac35f466af1ea2b0ae853bfe5e8f057fb1d6fb62db131707bb67b30d"
    },
    "permissions": [],
    "submission_state": "open",
    "default_currency": "usd",
    "awards_miles": false,
    "offers_bounties": true,
    "state": "public_mode",
    "only_cleared_hackers": false,
    "pentest_feature_enabled?": false,
    "pentest_retesting_ends_at": null,
    "profile": {
      "name": "curl",
      "twitter_handle": "",
      "website": "https://curl.se",
      "about": "cURL is an Open Source project providing a library and command-line tool doing internet transfers"
    }
  },
  "has_bounty?": false,
  "can_view_team": true,
  "can_view_report": true,
  "is_external_bug": false,
  "is_published": false,
  "is_participant": false,
  "has_collaborators": false,
  "submitted_by_team_member": false,
  "stage": 4,
  "public": true,
  "visibility": "full",
  "cve_ids": [],
  "singular_disclosure_disabled": true,
  "disclosed_at": "2025-07-14T11:31:57.138Z",
  "bug_reporter_agreed_on_going_public_at": null,
  "team_member_agreed_on_going_public_at": "2025-07-14T11:30:33.841Z",
  "comments_closed?": false,
  "facebook_team?": false,
  "team_private?": false,
  "vulnerability_information": "# Description\n\nThe tool_debug_cb function can write large amounts of debug data to a log file if the --trace or --trace-ascii options are used with a large volume of data. If an attacker can cause cURL to download or upload a very large amount of data (e.g., via a very large HTTP response or an unlimited upload), the log file generated by this debug function can grow indefinitely. This can lead to disk space exhaustion on the system where cURL is running, which in turn can disrupt other services running on the same server.\n\nThis section writes raw HTTP header data to the heads->stream if --dump-header is used. If heads->stream happens to be the same file as the trace output, or if it's another file with unlimited growth potential, it contributes to the problem.\n\n```\n/* In tool_debug_cb */\nif(per->config->headerfile && heads->stream) {\n    size_t rc = fwrite(ptr, size, nmemb, heads->stream); // <-- Vulnerable write\n    if(rc != cb)\n      return rc;\n    /* flush the stream to send off what we got earlier */\n    if(fflush(heads->stream)) {\n      errorf(per->config->global, \"Failed writing headers to %s\",\n                     per->config->headerfile);\n      return CURL_WRITEFUNC_ERROR;\n    }\n}\n```\n\nWhen global->tracetype == TRACE_PLAIN, this block handles text, headers, and data alerts.\n\n```\n/* In tool_debug_cb, in the TRACE_PLAIN section */\ncase CURLINFO_HEADER_OUT:\n    if(size > 0) {\n        size_t st = 0;\n        size_t i;\n        for(i = 0; i < size - 1; i++) {\n          if(data[i] == '\\n') { /* LF */\n            if(!newl) {\n              log_line_start(output, timebuf, idsbuf, type);\n            }\n            (void)fwrite(data + st, i - st + 1, 1, output); // <-- Vulnerable write\n            st = i + 1;\n            newl = FALSE;\n          }\n        }\n        if(!newl)\n          log_line_start(output, timebuf, idsbuf, type);\n        (void)fwrite(data + st, i - st + 1, 1, output); // <-- Vulnerable write\n    }\n    newl = (size && (data[size - 1] != '\\n'));\n    traced_data = FALSE;\n    break;\ncase CURLINFO_TEXT:\ncase CURLINFO_HEADER_IN:\n    if(!newl)\n      log_line_start(output, timebuf, idsbuf, type);\n    (void)fwrite(data, size, 1, output); // <-- Vulnerable write\n    newl = (size && (data[size - 1] != '\\n'));\n    traced_data = FALSE;\n    break;\n```\n\n```\ncase CURLINFO_DATA_OUT:\ncase CURLINFO_DATA_IN:\ncase CURLINFO_SSL_DATA_IN:\ncase CURLINFO_SSL_DATA_OUT:\n    if(!traced_data) {\n        // ...\n        fprintf(output, \"[%zu bytes data]\\n\", size); // <-- Vulnerable write\n        newl = FALSE;\n        traced_data = TRUE;\n    }\n    break;\n```\n\nThis is the most significant contributor to the vulnerability when --trace-ascii or --trace-bin is used, as it meticulously logs every byte of transferred data (headers, actual data, SSL data) in a formatted way.\n\n```\n/* In function dump */\n// ...\nfprintf(stream, \"%s%s%s, %zu bytes (0x%zx)\\n\", timebuf, idsbuf,\n             text, size, size); // <-- Vulnerable write (initial line)\n\nfor(i = 0; i < size; i += width) {\n\n    fprintf(stream, \"%04zx: \", i); // <-- Vulnerable write (line prefix)\n\n    if(tracetype == TRACE_BIN) {\n        for(c = 0; c < width; c++)\n            if(i + c < size)\n              fprintf(stream, \"%02x \", ptr[i + c]); // <-- Vulnerable write (hex data)\n            else\n              fputs(\"   \", stream); // <-- Vulnerable write (padding)\n    }\n\n    for(c = 0; (c < width) && (i + c < size); c++) {\n        // ...\n        fprintf(stream, \"%c\", ((ptr[i + c] >= 0x20) && (ptr[i + c] < 0x7F)) ?\n                     ptr[i + c] : UNPRINTABLE_CHAR); // <-- Vulnerable write (ASCII representation)\n        // ...\n    }\n    fputc('\\n', stream); // <-- Vulnerable write (newline character)\n}\nfflush(stream);\n```\n\nIn essence, the vulnerability isn't a bug in the fwrite or fprintf calls themselves, but rather the lack of a protective wrapper or check around these calls to limit the cumulative data written to the trace log file. The fix involves adding that missing check.\n\n# POC\n\n1. Unlimited data server setup [unli.py]\n\n```\nimport http.server\nimport socketserver\nimport time\n\nPORT = 8002\n\nclass MyHandler(http.server.SimpleHTTPRequestHandler):\n    def do_GET(self):\n        print(f\"[{time.ctime()}] Received GET request from {self.client_address[0]}\")\n        self.send_response(200)\n        self.send_header(\"Content-Type\", \"application/octet-stream\")\n        self.send_header(\"Transfer-Encoding\", \"chunked\")\n        # FIX: Changed self0 to self\n        self.end_headers()\n\n        # Stream data continuously\n        try:\n            i = 0\n            while True:\n                chunk = f\"This is chunk {i}: {'A' * 1024}\\n\".encode('utf-8') # 1KB of data per chunk\n                self.wfile.write(f\"{len(chunk):X}\\r\\n\".encode('ascii')) # Chunk size in hexadecimal\n                self.wfile.write(chunk)\n                self.wfile.write(b\"\\r\\n\")\n                self.wfile.flush()\n                i += 1\n                # Optional: add a small delay to observe file growth more easily\n                # time.sleep(0.01)\n        except Exception as e:\n            print(f\"[{time.ctime()}] Client disconnected or error: {e}\")\n        finally:\n            # End chunked encoding\n            self.wfile.write(b\"0\\r\\n\\r\\n\")\n            self.wfile.flush()\n\nwith socketserver.TCPServer((\"\", PORT), MyHandler) as httpd:\n    print(f\"serving at port {PORT}\")\n    try:\n        httpd.serve_forever()\n    except KeyboardInterrupt:\n        print(\"\\nServer shutting down.\")\n```\n\n{F4562562}\n\n2. Run curl with the trace option: Open a second terminal and execute the curl command.\n\n```\ncurl http://localhost:8002/test.txt -o /dev/null --trace output.log\n```\n\n```\n└─# curl http://localhost:8002/test.txt -o /dev/null --trace output.log\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100 37.0M    0 37.0M    0     0  7857k      0 --:--:--  0:00:04 --:--:-- 7856k\n```\n\nYou will now observe output.log rapidly increasing in size as the server continuously streams data and curl logs every bit of it. This demonstrates the Disk Space Exhaustion leading to a Denial of Service (DoS).\n\n# HOW TO FIX\n\nTo address the disk space exhaustion vulnerability you've demonstrated, the primary fix needs to focus on the code sections that write data to the trace log file without any size limitations. In the code snippet you provided, the most relevant places for implementation are:\n\nBefore every fwrite() or fprintf() operation directed to output (or heads->stream): This is where actual data is written to the file. You'll need to add a file size check here.\n\nWithin the dump() function: The dump() function is responsible for writing the formatted binary or ASCII data. This is a critical location because large amounts of data are processed and written to the output here.\n\nHere are the specific areas in your code that would require modification:\n\na. In tool_debug_cb():\nAt the beginning of the function, before any writes to output or heads->stream occur, you'd perform the check.\n```\nint tool_debug_cb(CURL *handle, curl_infotype type,\n                  char *data, size_t size,\n                  void *userdata)\n{\n  struct OperationConfig *operation = userdata;\n  struct GlobalConfig *global = operation->global;\n  FILE *output = tool_stderr;\n  // ... other variable declarations ...\n\n  // --- START FIX ---\n  // Ensure the trace stream is open and we have a size limit set\n  if (global->trace_stream && global->trace_fopened && global->max_trace_log_size > 0) {\n      // Estimate the size of the data to be written for this chunk\n      // This `estimated_write_size` function would need to be created.\n      // It should account for formatting overhead (e.g., hex dump takes more space).\n      size_t estimated_write_size = estimate_formatted_data_size(type, size, global->tracetype);\n\n      // Check if the current write would exceed the limit\n      if (global->current_trace_log_size + estimated_write_size > global->max_trace_log_size) {\n          // Close the file and disable tracing to prevent further writes\n          warnf(global, \"Trace log file '%s' reached maximum size (%s). Stopping further trace logging.\",\n                global->trace_dump, /* format size with a helper like tool_strbytel(global->max_trace_log_size) */);\n          fclose(global->trace_stream);\n          global->trace_stream = NULL; // Ensure no more writes happen\n          global->trace_fopened = FALSE;\n          // You might also want to disable the tracing option completely\n          global->tracetype = TRACE_NONE;\n          global->trace_dump = NULL;\n          return 0; // Stop the callback from processing further\n      }\n  }\n  // --- END FIX ---\n\n  // ... rest of tool_debug_cb code ...\n\n  // Section where headerfile is written:\n  if(per->config->headerfile && heads->stream) {\n    size_t rc = fwrite(ptr, size, nmemb, heads->stream);\n    // --- START FIX (Conditional) ---\n    // Update current_trace_log_size IF heads->stream is the designated trace_stream.\n    // This might require a check if heads->stream is the same as global->trace_stream.\n    // Alternatively, if `headerfile` is a distinct concept from `trace_dump`,\n    // it might need its own size limit mechanism. For simplicity, we assume\n    // 'output' is the main stream to monitor.\n    if (heads->stream == global->trace_stream) { // Example condition\n        global->current_trace_log_size += rc;\n    }\n    // --- END FIX ---\n    if(rc != cb)\n      return rc;\n    // ...\n  }\n\n  // TRACE_PLAIN section (CURLINFO_HEADER_OUT, CURLINFO_TEXT, CURLINFO_HEADER_IN, etc.):\n  // At each `fwrite` or `fprintf` location in this section:\n  // After each successful `fwrite` or `fprintf` call:\n  // global->current_trace_log_size += <number of bytes written>;\n  // Example for CURLINFO_TEXT/HEADER_IN:\n  // (void)fwrite(data, size, 1, output);\n  // if (output == global->trace_stream) { // Check if output is the trace stream\n  //     global->current_trace_log_size += size;\n  // }\n\n  // ...\n  // CURLINFO_DATA_OUT/IN/SSL_DATA_OUT/IN in TRACE_PLAIN:\n  // fprintf(output, \"[%zu bytes data]\\n\", size);\n  // if (output == global->trace_stream) { // Check\n  //     global->current_trace_log_size += strlen(\"[X bytes data]\\n\") + (number of digits in size); // Approximate\n  // }\n\n  // ... Call to dump() ...\n  // The dump() function will handle its own size increment internally,\n  // or it could return the number of bytes written for tool_debug_cb to add.\n  dump(timebuf, idsbuf, text, output, (unsigned char *) data, size,\n       global->tracetype, type, global); // Pass global config to dump\n  return 0;\n}\n```\n\nb. In the dump() function:\ndump() writes a lot of data, so it's an efficient place to update current_trace_log_size. You'll need to pass the GlobalConfig to dump to access current_trace_log_size.\n\n```\nstatic void dump(const char *timebuf, const char *idsbuf, const char *text,\n                 FILE *stream, const unsigned char *ptr, size_t size,\n                 trace tracetype, curl_infotype infotype, struct GlobalConfig *global) // Added global parameter\n{\n  size_t i;\n  size_t c;\n  unsigned int width = 0x10;\n\n  if(tracetype == TRACE_ASCII)\n    width = 0x40;\n\n  // --- START FIX ---\n  // Add the size of the initial line to the total\n  int written_bytes = fprintf(stream, \"%s%s%s, %zu bytes (0x%zx)\\n\", timebuf, idsbuf, text, size, size);\n  if (global && stream == global->trace_stream && written_bytes > 0) {\n      global->current_trace_log_size += written_bytes;\n  }\n  // --- END FIX ---\n\n\n  for(i = 0; i < size; i += width) {\n    // --- START FIX ---\n    // Check limit before writing each line\n    if (global && stream == global->trace_stream && global->current_trace_log_size >= global->max_trace_log_size) {\n        // If already over limit, just break and flush remaining\n        break;\n    }\n    // --- END FIX ---\n\n    // Write line header (e.g., \"0000: \")\n    written_bytes = fprintf(stream, \"%04zx: \", i);\n    if (global && stream == global->trace_stream && written_bytes > 0) {\n        global->current_trace_log_size += written_bytes;\n    }\n\n    if(tracetype == TRACE_BIN) {\n      for(c = 0; c < width; c++)\n        if(i + c < size) {\n          written_bytes = fprintf(stream, \"%02x \", ptr[i + c]);\n          if (global && stream == global->trace_stream && written_bytes > 0) {\n              global->current_trace_log_size += written_bytes;\n          }\n        } else {\n          written_bytes = fputs(\"   \", stream);\n          if (global && stream == global->trace_stream && written_bytes > 0) {\n              global->current_trace_log_size += written_bytes;\n          }\n        }\n    }\n\n    for(c = 0; (c < width) && (i + c < size); c++) {\n      // ... (CRLF handling logic remains) ...\n      written_bytes = fprintf(stream, \"%c\", ((ptr[i + c] >= 0x20) && (ptr[i + c] < 0x7F)) ?\n                               ptr[i + c] : UNPRINTABLE_CHAR);\n      if (global && stream == global->trace_stream && written_bytes > 0) {\n          global->current_trace_log_size += written_bytes;\n      }\n      // ... (CRLF handling logic) ...\n    }\n    written_bytes = fputc('\\n', stream); // newline\n    if (global && stream == global->trace_stream && written_bytes > 0) {\n        global->current_trace_log_size += written_bytes;\n    }\n  }\n  fflush(stream);\n}\n```\n\n# Additional \nDisabling Tracing: Once the limit is hit, it's crucial to effectively disable the tracing mechanism (e.g., by setting global->trace_stream = NULL and changing global->tracetype to TRACE_NONE) to prevent any further attempts to write.\n\n## Impact\n\nSystem Instability and Crash (High Impact)",
  "weakness": {
    "id": 1598,
    "name": "LLM04: Model Denial of Service"
  },
  "original_report_id": null,
  "original_report_url": null,
  "attachments": [
    {
      "id": 4562562,
      "file_name": "image.png",
      "expiring_url": "https://hackerone-us-west-2-production-attachments.s3.us-west-2.amazonaws.com/autz4cc8rrpkni87a555pbive71r?response-content-disposition=attachment%3B%20filename%3D%22image.png%22%3B%20filename%2A%3DUTF-8%27%27image.png&response-content-type=image%2Fpng&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIAQGK6FURQ6VGQJ6UU%2F20250714%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20250714T121509Z&X-Amz-Expires=3600&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEBIaCXVzLXdlc3QtMiJHMEUCIQCzK3K8PfZdbEidh9E84zNR6tP7uKiCLq5rqRaD8G%2BkbgIgZMiUP%2FxOAygkn5SQn73JLdR4PVFglXgpRoStTdoD31YqsgUIKxADGgwwMTM2MTkyNzQ4NDkiDDpllZ0vqBMOm22NkCqPBeTXzRHMZ21jMXPTBGi9TFnHuq7Tcto6ErO4b95gve2UrqTa9FgCV24iWLLrvxzPR0uHze3zJOur80s5E4GGnWP8mrrLfMcBs4j%2BRh9eJbA12JMRKWeVhlIQzV3Cp9N9FZq8a6r2WK0tJbSUUX%2BhU7MhsggM2Vrlumh4fCLCcPnyNJkE1ILXuQWOBCAaKPyTG6hT1xUzDJoN1kIR1opMuxsEZq4xfN9sHHmmdTU9%2Bl6HN%2FVXkb5XdrzMSl0%2FXSa4UhnctIVtsi57Qs6saddCQuapC%2BK%2FG5kTg5X1wQwS%2BJfASnuNcocoCy0MEgd8VVJvhlmQaK91BFa5OqJpa9cN4rSIRLbIOfsgkK3UX0kATH0NWUH7UUu9ds8InGCdATpeGGla5ctcXkIRIp7%2BZIUQ49DgxJYQiZSxEwxgSSofgeZUeZ1orm%2FWlERDVWCsbz8B%2F1C1fsHIKNnyZNW8Ol7buM%2FPHznA8Kzxw14hohxzo%2BVLjrbNjyLZigEFRg12JQ3NfYwHG0vkfYZmgt0oZxhkdg%2FOIRKui0npnf%2Bq2b%2BUqfw9V23QaDmcn0AOH5cM6AIbixbA%2Fs1qmShyxLk6%2BOhoMULplt39WJJZLG3ACTeiLOxSedPNu191vI9XiE5J%2B%2FR8kls44%2FCF4afcQClvZnHzVuGHBt9pbaw2lxOt4WHhVoAHkbBymVEl%2BduIQ1Mp4ozxSAEHYv%2BYAKkUIW9qnua2MrrYz7jXq39BGQlNgUkM%2B0VIzShxqnmJHbyuyDLPBqflcOyGJloMyRoqYBcNdT59VYyLm0l13zQtbtMHgwGuRlp%2B9o4bWwiBmtqIk02lJHHZIBGFpzwAF0Q8xvIjLYaryphS5VTQCyFZCmMgIcNKRIswzaXTwwY6sQHkp%2Bg1rhD%2Fuua%2BxIsLKnZL9uBuGkjg6pJ%2FQFcnDJmncCUfMv3EBqgIHHBPdEiSlEiyAVaueKE4IYDTS8bYrPEpzfrUToh84p0k1FkdB2UD%2BWKNa%2FDuYJoIyRmYH7MsxQza3CghzcV8aipeKpwMDFijps4jRiadjfriMqzgV4SmBRb%2Bm%2BIJKPWUpJ1Zvb8JaWFiHmrZ55zIgdT2GbcL45yd2wxWgZ714gBJBdp%2Bkm8b4W8%3D&X-Amz-SignedHeaders=host&X-Amz-Signature=864f092dbd527707f804fab6c355b317058cebd1e7463e90fdfcbfce0670e2ce",
      "file_size": 75753,
      "type": "image/png",
      "moderated": false
    }
  ],
  "allow_singular_disclosure_at": null,
  "vote_count": 0,
  "voters": [],
  "severity": {
    "rating": "medium",
    "author_type": "User"
  },
  "structured_scope": {
    "databaseId": 18844,
    "asset_type": "SOURCE_CODE",
    "asset_identifier": "https://github.com/curl/curl",
    "max_severity": "critical"
  },
  "abilities": {
    "assignable_team_members": [],
    "assignable_team_member_groups": []
  },
  "summaries": [
    {
      "category": "team",
      "can_view?": true,
      "can_create?": false
    },
    {
      "category": "researcher",
      "can_view?": true,
      "can_create?": false
    }
  ]
}
